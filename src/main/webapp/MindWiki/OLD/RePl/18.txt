* InterWiki: [WikiPedia:Read-eval-print_loop], [WikiWikiWeb:ReadEvalPrintLoop]

useful for ReplClj:

!list tables:
{{{
(let
 [hConf (new org.apache.hadoop.hbase.HBaseConfiguration)
  hBase (new org.apache.hadoop.hbase.client.HBaseAdmin hConf) ]
  (apply str
   (map
    (fn [x]
     (str
        (.getNameAsString x) " - " ))
       (.listTables hBase))
    )
  )
)
}}}

!list tables with column families
{{{
(let
 [hConf (new org.apache.hadoop.hbase.HBaseConfiguration)
  hBase (new org.apache.hadoop.hbase.client.HBaseAdmin hConf) ]
  (apply str
   (map
    (fn [table]
     (str
        "<b>" (.getNameAsString table) ":</b> "
        (apply 
          str
          (map
            (fn [col] (str (.getNameAsString col) " - "))
            (.getColumnFamilies table)))
        "<br/>"
        ))
       (.listTables hBase))
    )
  )
)
}}}

!create table:
{{{
(let
 [hConf (new org.apache.hadoop.hbase.HBaseConfiguration)
  hBase (new org.apache.hadoop.hbase.client.HBaseAdmin hConf)
  newTableDesc (new org.apache.hadoop.hbase.HTableDescriptor "MindId")]
 (do
  (.addFamily
   newTableDesc
   (new org.apache.hadoop.hbase.HColumnDescriptor "id:"))
  (.createTable hBase newTableDesc)))
}}}

!scan rows
{{{
(let 
 [hConf (new org.apache.hadoop.hbase.HBaseConfiguration)
  hTable (new org.apache.hadoop.hbase.client.HTable hConf "EventLog")]
 ((defn scanRow [zz]
   (let
    [next (.next zz)]
    (if next
     (str
      "<li>"
        (org.apache.hadoop.hbase.util.Base64/encodeBytes
          (.getRow next)) ": "
        (apply str
         (map
          (fn [x]
            (str
              "<br/>" (new String x) ": "
              (new String (.getValue (.get next x))) ))
         (.keySet next))) 
      "</li>"
      (scanRow zz))))
     )
      (.getScanner hTable (into-array ["log:"]))
     )))
}}}

!scan rows for specific columns:
{{{
(let 
 [hConf (new org.apache.hadoop.hbase.HBaseConfiguration)
  hTable (new org.apache.hadoop.hbase.client.HTable hConf "MindId")]
 ((defn scanRow [zz]
   (let
    [next (.next zz)]
    (if next
     (str
      "<li>" 
        (org.apache.hadoop.hbase.util.Bytes/toLong (.getRow next)) ": "
        (new String (.getValue (.get next "id:WikiHomePage")))
      "</li>"
      (scanRow zz))))
     )
      (.getScanner hTable (into-array ["id:"]))
     )))
}}}


!add row
{{{
(let
 [hConf (new org.apache.hadoop.hbase.HBaseConfiguration)
  hTable (new org.apache.hadoop.hbase.client.HTable hConf "MindId")
  batch
   (new org.apache.hadoop.hbase.io.BatchUpdate 
    (org.apache.hadoop.hbase.util.Bytes/toBytes (long 1))]
     (do
       (.put batch
           "id:WikiHomePage"
            (.getBytes "RainerWasserfuhr"))
       (.commit hTable batch))))
}}}

!delete specific row
{{{
(let
 [hConf (new org.apache.hadoop.hbase.HBaseConfiguration)
  hTable (new org.apache.hadoop.hbase.client.HTable hConf "EventLog")]
 (do
  (.deleteAll hTable
   (org.apache.hadoop.hbase.util.Base64/decode "AAAAAAAAAAE="))))
}}}

!memory
{{{
(.totalMemory (Runtime/getRuntime))
}}}

!test
{{{
       (if
         (.getParameter request "text")
         (let
             [batch
               (new org.apache.hadoop.hbase.io.BatchUpdate 
               (.toString (- (Long/MAX_VALUE) (.getTime (new java.util.Date)))))]
             (do
               (.put batch
                "log:date"
                 (.getBytes (.getParameter request "text")))
               (.put batch
                "log:session"
                 (.getBytes (.getId (.getSession request))))
               (.put batch
                "log:user"
                 (.getBytes 
                     (if (.equals "FFC9D312FEE1A39576255B04E53DEBF"
                           (.getId (.getSession request)))
                       "RainerWasserfuhr"
                       (.getRemoteHost request))))
               (.commit
                 (new org.apache.hadoop.hbase.client.HTable hConf "ChatLog")
                 batch)))
}}}

!NachBarn
{{{
(apply str 
  (map (fn [x]
    (let [
      line (.split x "	")  
      id (first line)  
      wikiName (second line) 
      fbLine (re-find #"\|\[XingLe:([a-zA-Z_0-9]+)\]" 
  (fetch-url-s (str "http://mindbroker.de/wiki/" wikiName "?skin=raw")))
   ]
        (str "<br/>" id " - " wikiName " - " (if fbLine (second fbLine))))
  ) (.split "1	RainerWasserfuhr
2	YvonneSchubert
3	DanielPoodratchi
...
117	JuergenAnke" "\r")))
}}}

{{{
(sort-by (fn [e] (second e)) [[1 99] [3 4] [5 6] [7 8]])
}}}

!Random CamelCase word
{{{
(str 
 (new Character (char (+ 65 (.nextInt (new java.util.Random) 26))))
 (new Character (char (+ 97 (.nextInt (new java.util.Random) 26))))
 (new Character (char (+ 65 (.nextInt (new java.util.Random) 26))))
 (new Character (char (+ 97 (.nextInt (new java.util.Random) 26)))))
}}}

!EnTrop
{{{
(apply str
 (map 
  (fn [x]
   (str " "
    (new Character (char (+ 65 (.nextInt (new java.util.Random) 26))))
    (new Character (char (+ 97 (.nextInt (new java.util.Random) 26))))
    (new Character (char (+ 65 (.nextInt (new java.util.Random) 26))))
    (new Character (char (+ 97 (.nextInt (new java.util.Random) 26))))))
  (range 256)))
}}}

{{{
(let
 [feed (:content (clojure.xml/parse "http://mindbroker.de/rss.rdf"))
  sdf (new java.text.SimpleDateFormat "yyyy-MM-dd'T'HH:mm:ss")
  len (.length feed)]
 (apply str
  (map
   (fn [x]
    (let [
     item (:content (get feed (+ x 1)))
     title (get (:content (get item 0)) 0)
     version (get (:content (get item 3)) 0)
     dIndex (if (.equals "1" version) 4 5)
     dateString (get (:content (get item dIndex)) 0)
     author (get (:content (get item (+ dIndex 1))) 0)
     date (.parse sdf dateString)]
    [date :rss author title]))
    (range (- len 1)))
))

}}}

{{{
(let
 [hConf (new org.apache.hadoop.hbase.HBaseConfiguration)
  hTable (new org.apache.hadoop.hbase.client.HTable hConf "EventLog")
  filter (new org.apache.hadoop.hbase.filter.ColumnValueFilter
    (org.apache.hadoop.hbase.util.Bytes/toBytes "log:MindId")
    org.apache.hadoop.hbase.filter.ColumnValueFilter$CompareOp/EQUAL
    (org.apache.hadoop.hbase.util.Bytes/toBytes "1"))
  scan (new org.apache.hadoop.hbase.client.Scan)
  scanner scan
 ]
 ((defn scanRow [zz]
   (let
    [next (.next zz)]
    (if next
     (str
      "<li>"
        (org.apache.hadoop.hbase.util.Bytes/toLong (.getRow next)) ": "
      "</li>"
      (scanRow zz))))
     )
      (.getScanner hTable scan)
     )))
}}}
